{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook I am using pytorch as it is really suitable for building from scratch neural networks\n",
    "### I will build a variational autoencoder for 1D input data specifically time-series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 16      # initial depth to convolve channels into\n",
    "filt_size = 4   # convolution filter size\n",
    "stride = 2      # stride for conv\n",
    "pad = 1         # padding added for conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.encoder = nn.Sequential()  \n",
    "        # input: n_channels x size\n",
    "        # ouput: depth x conv_size\n",
    "        # conv_size = (size - filt_size + 2 * pad) / stride + 1\n",
    "        self.encoder.add_module('input1', nn.Conv1d(n_channels, depth,\n",
    "                                                        filt_size, stride, pad,\n",
    "                                                        bias=True))\n",
    "        self.encoder.add_module('input2', nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Add conv layer \n",
    "        # Pyramid strategy pooling and batch normalization \n",
    "        for i in range(n - 3):\n",
    "            # input: i_depth x conv_size\n",
    "            # output: o_depth x conv_size\n",
    "            # i_depth = o_depth of previous layer\n",
    "            i_depth = depth * 2 ** i\n",
    "            o_depth = depth * 2 ** (i + 1)\n",
    "            self.encoder.add_module(f'pyramid_{i_depth}-{o_depth}_conv',\n",
    "                                    nn.Conv1d(i_depth, o_depth, filt_size, stride, pad, bias=True))\n",
    "            self.encoder.add_module(f'pyramid_{o_depth}_batchnorm',\n",
    "                                    nn.BatchNorm1d(o_depth))\n",
    "            self.encoder.add_module(f'pyramid_{o_depth}_relu',\n",
    "                                    nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution of encoded vector into the latent space\n",
    "max_depth = depth * 2 ** (n - 3)\n",
    "self.conv_mu = nn.Conv1d(max_depth, n_latent, filt_size)\n",
    "self.conv_logvar = nn.Conv1d(max_depth, n_latent, filt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder - second half of VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.decoder = nn.Sequential()\n",
    "# input: max_depth x conv_size\n",
    "# output: n_latent x conv_size\n",
    "# default stride=1, pad=0 for this layer\n",
    "self.decoder.add_module('input1', nn.ConvTranspose1d(n_latent, max_depth, filt_size, bias=True))\n",
    "self.decoder.add_module('input2', nn.BatchNorm1d(max_depth))\n",
    "self.decoder.add_module('input3', nn.ReLU(inplace=True))\n",
    "    \n",
    "# Reverse the convolution pyramids used in the encoder\n",
    "for i in range(n - 3, 0, -1):\n",
    "    \n",
    "    i_depth = depth * 2 ** i\n",
    "    o_depth = depth * 2 ** (i - 1)\n",
    "    self.decoder.add_module(f'pyramid_{i_depth}-{o_depth}_conv',\n",
    "                                    nn.ConvTranspose1d(i_depth, o_depth, filt_size, stride, pad, bias=True))\n",
    "    self.decoder.add_module(f'pyramid_{o_depth}_batchnorm',\n",
    "                                    nn.BatchNorm1d(o_depth))\n",
    "    self.decoder.add_module(f'pyramid_{o_depth}_relu', nn.ReLU(inplace=True))\n",
    "        \n",
    "# Final transposed convolution to return to vector size\n",
    "# TODO: ?No final activation to allow unbounded numerical output\n",
    "    self.decoder.add_module('output-conv', nn.ConvTranspose1d(depth, n_channels,\n",
    "                                                                  filt_size, stride, pad,\n",
    "                                                                  bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction loss\n",
    "        batch_size = trans.shape[0]\n",
    "    \n",
    "        gen_err = (trans - gen_trans).pow(2).reshape(batch_size, -1)\n",
    "        gen_err = 0.5 * torch.sum(gen_err, dim=-1)  \n",
    "        \n",
    "        if reduce:\n",
    "            gen_err = torch.mean(gen_err)\n",
    "        \n",
    "        # Regularizer\n",
    "\n",
    "        KL = (-logvar + logvar.exp() + mu.pow(2) - 1) * 0.5\n",
    "        KL = torch.sum(KL, dim=-1)\n",
    "        \n",
    "        if reduce:\n",
    "            KL = torch.mean(KL)\n",
    "            \n",
    "        loss = gen_err + self.beta * KL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
